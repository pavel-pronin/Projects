{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#%pip install --upgrade transformers datasets accelerate deepspeed\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport transformers\nimport datasets\nimport tqdm \nimport numpy as np\nimport torchmetrics\nimport os\nimport time\nimport psutil\nimport platform\nimport cpuinfo\n!pip install GPUtil\nimport GPUtil\nfrom tabulate import tabulate\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-05T14:21:50.207158Z","iopub.execute_input":"2023-05-05T14:21:50.207735Z","iopub.status.idle":"2023-05-05T14:22:00.030871Z","shell.execute_reply.started":"2023-05-05T14:21:50.207689Z","shell.execute_reply":"2023-05-05T14:22:00.029625Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: GPUtil in /opt/conda/lib/python3.10/site-packages (1.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load Data and Model","metadata":{}},{"cell_type":"code","source":"qqp = datasets.load_dataset('SetFit/qqp')\nprint('\\n')\nprint(\"Sample[0]:\", qqp['train'][0])\nprint(\"Sample[3]:\", qqp['train'][3])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:22:00.033881Z","iopub.execute_input":"2023-05-05T14:22:00.034285Z","iopub.status.idle":"2023-05-05T14:22:07.317427Z","shell.execute_reply.started":"2023-05-05T14:22:00.034244Z","shell.execute_reply":"2023-05-05T14:22:07.316152Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/SetFit--qqp to /root/.cache/huggingface/datasets/json/SetFit--qqp-94258451190e12bb/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea29077669449ebac6877398166e4b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/70.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7065e23203fa42bb8809b3ffdf451f87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/76.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7f8abcf9d4c481a8cab4b3d9bd06c7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/7.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b5b463e103e4d8a8d0da6e4e6ac9e05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b4f8fad314048d7ae2f4ea618c43d11"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/SetFit--qqp-94258451190e12bb/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf141600f4bf44268cd848215fe5faa2"}},"metadata":{}},{"name":"stdout","text":"\n\nSample[0]: {'text1': 'How is the life of a math student? Could you describe your own experiences?', 'text2': 'Which level of prepration is enough for the exam jlpt5?', 'label': 0, 'idx': 0, 'label_text': 'not duplicate'}\nSample[3]: {'text1': 'What can one do after MBBS?', 'text2': 'What do i do after my MBBS ?', 'label': 1, 'idx': 3, 'label_text': 'duplicate'}\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"gchhablani/bert-base-cased-finetuned-qqp\"\ntokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:22:28.649591Z","iopub.execute_input":"2023-05-05T14:22:28.650186Z","iopub.status.idle":"2023-05-05T14:22:41.118977Z","shell.execute_reply.started":"2023-05-05T14:22:28.650150Z","shell.execute_reply":"2023-05-05T14:22:41.117827Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23f728c41b95450e9da02bd6f3ced699"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92b37e9c90f4eafbd730afea3c58da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e0a3b94315742be9eff1e723558837e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"363cd5291d4e48028cdf6feddfda5547"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58793f9cbe774f52bd65daae35faafd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6c5d793e974034a8d677cb36c93813"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenize Data","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 128\ndef preprocess_function(examples):\n    result = tokenizer(\n        examples['text1'], examples['text2'],\n        padding='max_length', max_length=MAX_LENGTH, truncation=True\n    )\n    result['label'] = examples['label']\n    return result\n\nqqp_preprocessed = qqp.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:29:25.526803Z","iopub.execute_input":"2023-05-05T11:29:25.527491Z","iopub.status.idle":"2023-05-05T11:29:25.537614Z","shell.execute_reply.started":"2023-05-05T11:29:25.527452Z","shell.execute_reply":"2023-05-05T11:29:25.536440Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(repr(qqp_preprocessed['train'][0]['input_ids'])[:100], \"...\")","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:07:40.048301Z","iopub.execute_input":"2023-05-05T10:07:40.048647Z","iopub.status.idle":"2023-05-05T10:07:40.057739Z","shell.execute_reply.started":"2023-05-05T10:07:40.048616Z","shell.execute_reply":"2023-05-05T10:07:40.056879Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[101, 1731, 1110, 1103, 1297, 1104, 170, 12523, 2377, 136, 7426, 1128, 5594, 1240, 1319, 5758, 136,  ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Task 1: evaluation (1 points)\n","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 256\nNUM_WORKERS = 2\nDEVICE = 'cuda'\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nval_set = qqp_preprocessed['validation']\nval_loader = torch.utils.data.DataLoader(\n    val_set, batch_size=BATCH_SIZE, shuffle=False, collate_fn=transformers.default_data_collator,\n    num_workers = NUM_WORKERS\n)\n\npreds = []\nlabels = []\nwith torch.no_grad():\n    model.to(DEVICE)\n    for batch in tqdm.tqdm(val_loader):\n        prediction = model(\n          input_ids=batch['input_ids'].to(DEVICE),\n          attention_mask=batch['attention_mask'].to(DEVICE),\n          token_type_ids=batch['token_type_ids'].to(DEVICE)\n        )\n        labels.extend(batch['labels'].data.numpy())\n        prediction = torch.softmax(prediction.logits, dim = 1).cpu().data.numpy()\n        preds.extend(prediction)\n    \n\npreds = torch.tensor(preds)\ntarget = torch.nn.functional.one_hot(torch.tensor(labels))\naccuracy = torchmetrics.functional.classification.accuracy(preds = torch.tensor(preds),\n                                                target = target,\n                                                task = 'binary', top_k = 1).numpy()\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:07:54.456969Z","iopub.execute_input":"2023-05-05T10:07:54.458017Z","iopub.status.idle":"2023-05-05T10:10:07.767095Z","shell.execute_reply.started":"2023-05-05T10:07:54.457959Z","shell.execute_reply":"2023-05-05T10:10:07.765919Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 158/158 [02:13<00:00,  1.19it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.90838486\n","output_type":"stream"},{"name":"stderr","text":"\n/tmp/ipykernel_31/2489568406.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n  preds = torch.tensor(preds)\n/tmp/ipykernel_31/2489568406.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  accuracy = torchmetrics.functional.classification.accuracy(preds = torch.tensor(preds),\n","output_type":"stream"}]},{"cell_type":"code","source":"assert 0.9 < accuracy < 0.91","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:10:19.633462Z","iopub.execute_input":"2023-05-05T10:10:19.633841Z","iopub.status.idle":"2023-05-05T10:10:19.642374Z","shell.execute_reply.started":"2023-05-05T10:10:19.633803Z","shell.execute_reply":"2023-05-05T10:10:19.641329Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Task 2: train the model (5 points) -- Option B\n\nI take **Option B** and compare the following models:\n- ernie `rajiv003/ernie-finetuned-qqp`\n- DeBERTa `Tomor0720/deberta-base-finetuned-qqp`\n- XLNet `vkk1710/xlnet-base-cased-finetuned-qqp`","metadata":{}},{"cell_type":"markdown","source":"#### Hardware Setup","metadata":{}},{"cell_type":"code","source":"# 99% stolen from https://www.thepythoncode.com/article/get-hardware-system-information-python\n\ndef get_size(bytes, suffix=\"B\"):\n    factor = 1024\n    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if bytes < factor:\n            return f\"{bytes:.2f}{unit}{suffix}\"\n        bytes /= factor\n\nprint(\"=\"*40, \"System Information\", \"=\"*40)\nuname = platform.uname()\nprint(f\"System: {uname.system}\")\nprint(f\"Version: {uname.version}\")\nprint(f\"Machine: {uname.machine}\")\nprint(f\"Processor: {uname.processor}\")\nprint(f\"Python Version: {cpuinfo.get_cpu_info()['python_version']}\")\n\nprint(\"=\"*40, \"CPU Info\", \"=\"*40)\nprint(\"CPU:\", cpuinfo.get_cpu_info().get('brand_raw'))\nprint(\"Physical cores:\", psutil.cpu_count(logical=False))\nprint(\"Total cores:\", psutil.cpu_count(logical=True))\n\nprint(\"=\"*40, \"Memory Information\", \"=\"*40)\nsvmem = psutil.virtual_memory()\nprint(f\"Total: {get_size(svmem.total)}\")\nprint(f\"Available: {get_size(svmem.available)}\")\nprint(f\"Used: {get_size(svmem.used)}\")\n\nprint(\"=\"*40, \"GPU Details\", \"=\"*40)\ngpus = GPUtil.getGPUs()\nlist_gpus = []\nfor gpu in gpus:\n    gpu_id = gpu.id\n    gpu_name = gpu.name\n    gpu_load = f\"{gpu.load*100}%\"\n    gpu_free_memory = f\"{gpu.memoryFree}MB\"\n    gpu_used_memory = f\"{gpu.memoryUsed}MB\"\n    gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n    gpu_temperature = f\"{gpu.temperature} °C\"\n    gpu_uuid = gpu.uuid\n    list_gpus.append((\n        gpu_id, gpu_name, gpu_load, gpu_free_memory, gpu_used_memory,\n        gpu_total_memory, gpu_temperature, gpu_uuid\n    ))\n\nprint(tabulate(list_gpus, headers=(\"id\", \"name\", \"load\", \"free memory\", \"used memory\", \"total memory\",\n                                   \"temperature\", \"uuid\")))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:22:55.382983Z","iopub.execute_input":"2023-05-05T10:22:55.383379Z","iopub.status.idle":"2023-05-05T10:22:57.791980Z","shell.execute_reply.started":"2023-05-05T10:22:55.383323Z","shell.execute_reply":"2023-05-05T10:22:57.790439Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"======================================== System Information ========================================\nSystem: Linux\nVersion: #1 SMP Thu Apr 27 10:55:14 UTC 2023\nMachine: x86_64\nProcessor: x86_64\nPython Version: 3.10.10.final.0 (64 bit)\n======================================== CPU Info ========================================\nCPU: Intel(R) Xeon(R) CPU @ 2.00GHz\nPhysical cores: 1\nTotal cores: 2\n======================================== Memory Information ========================================\nTotal: 15.63GB\nAvailable: 13.14GB\nUsed: 2.17GB\n======================================== GPU Details ========================================\n  id  name                  load    free memory    used memory    total memory    temperature    uuid\n----  --------------------  ------  -------------  -------------  --------------  -------------  ----------------------------------------\n   0  Tesla P100-PCIE-16GB  0.0%    16280.0MB      0.0MB          16280.0MB       34.0 °C        GPU-c50c057d-272c-96e5-bf24-5eddfc8cfa57\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Functions to Run Benchmarks","metadata":{}},{"cell_type":"code","source":"def preprocess_function(examples, tokenizer):\n    result = tokenizer(\n        examples['text1'], examples['text2'],\n        padding='max_length', max_length=MAX_LENGTH, truncation=True\n    )\n    result['label'] = examples['label']\n    return result\n\ndef benchmark_model(model, tokenizer):\n    result_dict = {}\n    \n    print(\"=\"*40, \"Preprocessing.\", \"=\"*40)\n    qqp_preprocessed = qqp.map(lambda x: preprocess_function(x, tokenizer), \n                               batched=True)\n    val_set = qqp_preprocessed['validation']\n    val_loader = torch.utils.data.DataLoader(\n        val_set, batch_size=BATCH_SIZE, shuffle=False, collate_fn=transformers.default_data_collator,\n        num_workers = NUM_WORKERS\n        )\n    \n    print(\"=\"*40, \"Running Model.\", \"=\"*40)\n    start_time = time.time()\n    preds = []\n    labels = []\n    with torch.no_grad():\n        model.to(DEVICE)\n        for batch in tqdm.tqdm(val_loader):\n            prediction = model(\n            input_ids=batch['input_ids'].to(DEVICE),\n            attention_mask=batch['attention_mask'].to(DEVICE),\n            token_type_ids=batch['token_type_ids'].to(DEVICE)\n            )\n            labels.extend(batch['labels'].data.numpy())\n            prediction = torch.softmax(prediction.logits, dim = 1).cpu().data.numpy()\n            preds.extend(prediction)\n    result_dict['total_time'] = time.time() - start_time\n    \n    print(\"=\"*40, \"Estimating Accuracy.\", \"=\"*40)\n    preds = torch.tensor(preds)\n    target = torch.nn.functional.one_hot(torch.tensor(labels))\n    accuracy = torchmetrics.functional.classification.accuracy(preds = torch.tensor(preds),\n                                                    target = target,\n                                                    task = 'binary', top_k = 1).numpy()\n    result_dict['accuracy'] = accuracy\n    return result_dict","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:04:43.902998Z","iopub.execute_input":"2023-05-05T11:04:43.903377Z","iopub.status.idle":"2023-05-05T11:04:43.914363Z","shell.execute_reply.started":"2023-05-05T11:04:43.903343Z","shell.execute_reply":"2023-05-05T11:04:43.913251Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 256\nNUM_WORKERS = 2\nDEVICE = 'cuda' \nMAX_LENGTH = 128\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:32:34.533186Z","iopub.execute_input":"2023-05-05T12:32:34.533540Z","iopub.status.idle":"2023-05-05T12:32:34.538413Z","shell.execute_reply.started":"2023-05-05T12:32:34.533503Z","shell.execute_reply":"2023-05-05T12:32:34.537350Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Models","metadata":{}},{"cell_type":"code","source":"model_name_1 = \"rajiv003/ernie-finetuned-qqp\"\ntokenizer_1 = transformers.AutoTokenizer.from_pretrained(model_name_1)\nmodel_1 = transformers.AutoModelForSequenceClassification.from_pretrained(model_name_1)\nresult_1 = benchmark_model(model_1, tokenizer_1)\nresult_1['name'] = model_name_1\nresult_1['size'] = '438 Mbs'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:23:28.517873Z","iopub.execute_input":"2023-05-05T10:23:28.518213Z","iopub.status.idle":"2023-05-05T10:28:45.103082Z","shell.execute_reply.started":"2023-05-05T10:23:28.518185Z","shell.execute_reply":"2023-05-05T10:28:45.101936Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/377 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d034b17838ca453fbd7cab128bc6db76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef6c7172a5842898b317b8d01a0990a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98bd6123e9e54f1ebc00abbf5e7c3ccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a4feb3ebd44eaba4b7bc61ffce066e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/790 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ac1b8a48cd440299e3848114fa0375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8bdadc0f7c447af8e20ec923c47facd"}},"metadata":{}},{"name":"stdout","text":"======================================== Preprocessing. ========================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/364 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e0b955225b14801a057a6a8fbab6ad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/391 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3b3e48037b4c68ad26ec8ba68093e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/41 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a88805c029741f89eeed28b4e8cd2ec"}},"metadata":{}},{"name":"stdout","text":"======================================== Running Model. ========================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 158/158 [02:14<00:00,  1.17it/s]","output_type":"stream"},{"name":"stdout","text":"======================================== Estimating Accuracy. ========================================\n","output_type":"stream"},{"name":"stderr","text":"\n/tmp/ipykernel_31/1177051887.py:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n  preds = torch.tensor(preds)\n/tmp/ipykernel_31/1177051887.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  accuracy = torchmetrics.functional.classification.accuracy(preds = torch.tensor(preds),\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name_2 = \"Tomor0720/deberta-base-finetuned-qqp\"\ntokenizer_2 = transformers.AutoTokenizer.from_pretrained(model_name_2)\nmodel_2 = transformers.AutoModelForSequenceClassification.from_pretrained(model_name_2)\nresult_2 = benchmark_model(model_2, tokenizer_2)\nresult_2['name'] = model_name_2\nresult_2['size'] = '557 Mbs'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:28:51.044051Z","iopub.execute_input":"2023-05-05T10:28:51.044441Z","iopub.status.idle":"2023-05-05T10:34:40.025779Z","shell.execute_reply.started":"2023-05-05T10:28:51.044405Z","shell.execute_reply":"2023-05-05T10:34:40.024778Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d268cd0e934ca9ae2a1760eb54e415"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d9b7ac1b8c847b9964e1d988a3838d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c4f6d97991c475fbb520fa836c18af0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9146e5c9594b0fb0027c853dc64408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/963 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc84b2a70c9d43858d3024e10190e59b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb9b04c8d204c02a3c25bf80696f510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505c48b663b04340a306af30001502de"}},"metadata":{}},{"name":"stdout","text":"======================================== Preprocessing. ========================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/364 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"908c5e1c923343c0906c02fd82391afd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/391 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"180e9342cb124513bc05704c52fa8e79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/41 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9468a2e0d23c44f5b5ca33c3f546012e"}},"metadata":{}},{"name":"stdout","text":"======================================== Running Model. ========================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 158/158 [02:50<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"======================================== Estimating Accuracy. ========================================\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1177051887.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  accuracy = torchmetrics.functional.classification.accuracy(preds = torch.tensor(preds),\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name_3 = \"vkk1710/xlnet-base-cased-finetuned-qqp\"\ntokenizer_3 = transformers.AutoTokenizer.from_pretrained(model_name_3)\nmodel_3 = transformers.AutoModelForSequenceClassification.from_pretrained(model_name_3)\nresult_3 = benchmark_model(model_3, tokenizer_3)\nresult_3['name'] = model_name_3\nresult_3['size'] = '469 Mbs'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:35:00.653080Z","iopub.execute_input":"2023-05-05T10:35:00.653483Z","iopub.status.idle":"2023-05-05T10:42:01.081157Z","shell.execute_reply.started":"2023-05-05T10:35:00.653446Z","shell.execute_reply":"2023-05-05T10:42:01.079907Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/516 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420e2045c4cf49b583d902e34520899a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7344903b6ce7490c83c7929def99ac0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b72c28d7e6654aa5ab9fb51095cb5dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d9f06141b94228af247186c1cde2b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/469M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f86908727a40ada3cd3b77392a8c44"}},"metadata":{}},{"name":"stdout","text":"======================================== Preprocessing. ========================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/364 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228580a0784c4a33aa90d838ca7c3351"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/391 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11fec69ab10f47fa8348a0e0c3da01b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/41 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e4bd245106b44988fd6ae489f572c88"}},"metadata":{}},{"name":"stdout","text":"======================================== Running Model. ========================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 158/158 [03:47<00:00,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"======================================== Estimating Accuracy. ========================================\n","output_type":"stream"},{"name":"stderr","text":"\n/tmp/ipykernel_31/1177051887.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  accuracy = torchmetrics.functional.classification.accuracy(preds = torch.tensor(preds),\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Results\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torchinfo\n\nresult_1['params(in Mil.)'] = torchinfo.summary(model_1).total_params/1e6\nresult_2['params(in Mil.)'] = torchinfo.summary(model_2).total_params/1e6\nresult_3['params(in Mil.)'] = torchinfo.summary(model_3).total_params/1e6\n\nresults = pd.concat([pd.DataFrame(result_1, index = [0]),\n           pd.DataFrame(result_2, index = [0]),\n           pd.DataFrame(result_3, index = [0])], axis = 0).reset_index(drop=True)\nresults.index = results['name']\ndel results['name']\nresults['batchs/sec'] = 159/results['total_time']\nresults = results.loc[:, ['accuracy', 'batchs/sec', 'params(in Bil.)', 'size']]\nresults.sort_values('accuracy', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T10:53:48.995773Z","iopub.execute_input":"2023-05-05T10:53:48.996632Z","iopub.status.idle":"2023-05-05T10:53:49.072258Z","shell.execute_reply.started":"2023-05-05T10:53:48.996587Z","shell.execute_reply":"2023-05-05T10:53:49.071289Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"                                        accuracy  batchs/sec  params(in Bil.)  \\\nname                                                                            \nrajiv003/ernie-finetuned-qqp            0.915211    1.144554       109.485314   \nTomor0720/deberta-base-finetuned-qqp    0.912763    0.931496       139.193858   \nvkk1710/xlnet-base-cased-finetuned-qqp  0.908385    0.697106       117.310466   \n\n                                           size  \nname                                             \nrajiv003/ernie-finetuned-qqp            438 Mbs  \nTomor0720/deberta-base-finetuned-qqp    557 Mbs  \nvkk1710/xlnet-base-cased-finetuned-qqp  469 Mbs  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>batchs/sec</th>\n      <th>params(in Bil.)</th>\n      <th>size</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>rajiv003/ernie-finetuned-qqp</th>\n      <td>0.915211</td>\n      <td>1.144554</td>\n      <td>109.485314</td>\n      <td>438 Mbs</td>\n    </tr>\n    <tr>\n      <th>Tomor0720/deberta-base-finetuned-qqp</th>\n      <td>0.912763</td>\n      <td>0.931496</td>\n      <td>139.193858</td>\n      <td>557 Mbs</td>\n    </tr>\n    <tr>\n      <th>vkk1710/xlnet-base-cased-finetuned-qqp</th>\n      <td>0.908385</td>\n      <td>0.697106</td>\n      <td>117.310466</td>\n      <td>469 Mbs</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"As evident from the table above, all models perform comparable to base BERT specification with XLNet having almost identical performance on QQP. The best model of 3 compared is clearly the ERNIE as strictly dominates other models both in terms of accuracy, speed and size. ","metadata":{}},{"cell_type":"markdown","source":"### Task 3: try the full pipeline (2 points)\n\nFinally, it is time to use your model to find duplicate questions. Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n\nShowcase how your function works with at least 5 examples.","metadata":{}},{"cell_type":"markdown","source":"I will use **ERNIE** since it performs best.\n\n0. Running the loop honestly is very time consuming ($\\approx$ 27 minutes). \n1. Instead of doing it, I cheat a little bit and **sample batches** of given size $B$ from the train questions list $n$ times.\n    - Gives lower scores for matches, but actually sentences seem to be more related\n2. Instead of random sampling we can make procedure more intelligent by firstly making a restricted set of potential duplicates based on the common words (**Jaccard Distance**)\n    - Gives higher socres for matches, but sentences are poorly related\n\nIt turns out that **random sampling is better than using Jaccard Distance**. Moreover, obviously, as the number of sample increases, the method gets closer to fair approach.","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 128\nBATCH_SIZE = 256\nDEVICE = 'cuda'\nmodel_name_1 = \"rajiv003/ernie-finetuned-qqp\"\ntokenizer_1 = transformers.AutoTokenizer.from_pretrained(model_name_1)\nmodel_1 = transformers.AutoModelForSequenceClassification.from_pretrained(model_name_1).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:30:25.613344Z","iopub.execute_input":"2023-05-05T14:30:25.614039Z","iopub.status.idle":"2023-05-05T14:30:27.443587Z","shell.execute_reply.started":"2023-05-05T14:30:25.614003Z","shell.execute_reply":"2023-05-05T14:30:27.442614Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# sample of all train questions\ntrain_questions = []\nfor x in tqdm.tqdm(qqp['train']):\n    train_questions.extend([x['text1'], x['text2']])\ntrain_questions = list(set(train_questions))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:30:29.569264Z","iopub.execute_input":"2023-05-05T14:30:29.569670Z","iopub.status.idle":"2023-05-05T14:30:58.323135Z","shell.execute_reply.started":"2023-05-05T14:30:29.569636Z","shell.execute_reply":"2023-05-05T14:30:58.322148Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"100%|██████████| 363846/363846 [00:28<00:00, 12753.48it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_batch(k, question, model, tokenizer):\n    \"\"\"\n        * k -- index of batch\n    \"\"\"\n    candidates = train_questions[k*BATCH_SIZE: (k+1)*BATCH_SIZE]\n    questions = [question]*len(candidates)\n    pair = tokenizer(questions, candidates,  padding='max_length', \n                         max_length=MAX_LENGTH, truncation=True)\n    with torch.no_grad():\n        logits = model(input_ids=torch.tensor(pair['input_ids']).to(DEVICE),\n                        attention_mask=torch.tensor(pair['attention_mask']).to(DEVICE),\n                        token_type_ids=torch.tensor(pair['token_type_ids']).to(DEVICE)\n                     ).logits\n        score = torch.softmax(logits, dim = 1).cpu().numpy()\n    return score\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:31:01.202199Z","iopub.execute_input":"2023-05-05T14:31:01.202599Z","iopub.status.idle":"2023-05-05T14:31:01.209987Z","shell.execute_reply.started":"2023-05-05T14:31:01.202566Z","shell.execute_reply":"2023-05-05T14:31:01.208731Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport multiprocess as mp\nimport random\n\ndef common_words(question, candidate):\n    \"\"\"\n    This is essentially jaccard similarity\n    \"\"\"\n    total = len(set(question.split()).union(set(candidate.split())))\n    match = len(set(question.split()).intersection(set(candidate.split())))\n    return match/total\n\ndef process_question(question, model, tokenizer, \n                     method: str, # fair, sampling, restricted\n                     n_samples: int = 5, # number of samples for sampling methods \n                     r_size: int = 5000): # size of restricted sample\n    \n    population = train_questions\n    scores = []\n    k_max = int(len(population)/BATCH_SIZE) + 1\n    if method == 'fair':\n        for k in tqdm.trange(0, k_max):\n            scores_batch = process_batch(k, question, model, tokenizer)\n            scores.extend(scores_batch)\n    elif method == 'sampling':\n        assert isinstance(n_samples, int)\n        assert 0 < n_samples <= k_max\n        for k in tqdm.trange(n_samples):\n            sample = random.sample(population, BATCH_SIZE)\n            # update population by removing sample\n            population = list(set(population).difference(set(sample)))\n            # estimate batch\n            scores_batch = process_batch(k, question, model, tokenizer)\n            scores.extend(scores_batch)\n    elif method == 'restricted':\n        assert isinstance(r_size, int)\n        assert 1 < r_size <= len(population)\n        word_corr = np.array([common_words(question, x) for x in population])\n        candidates = np.array(population)[np.argsort(-word_corr)[:r_size]]\n        questions = [question]*len(candidates)\n        pair = tokenizer(list(questions), list(candidates),  padding='max_length', \n                         max_length=MAX_LENGTH, truncation=True)\n        k_max = int(len(candidates)/BATCH_SIZE) + 1\n        with torch.no_grad():\n            for k in tqdm.trange(k_max):\n                pair = tokenizer(list(questions)[k*BATCH_SIZE: (k+1)*BATCH_SIZE], \n                                 list(candidates)[k*BATCH_SIZE: (k+1)*BATCH_SIZE],  \n                                 padding='max_length', max_length=MAX_LENGTH, truncation=True)\n                logits = model(input_ids=torch.tensor(pair['input_ids']).to(DEVICE),\n                                attention_mask=torch.tensor(pair['attention_mask']).to(DEVICE),\n                                token_type_ids=torch.tensor(pair['token_type_ids']).to(DEVICE)\n                             ).logits\n                scores_batch = torch.softmax(logits, dim = 1).cpu().numpy()\n                scores.extend(scores_batch)\n        \n    scores_positive = np.array(scores)[:, 1]\n    top5_candidates = np.array(train_questions)[np.argsort(-scores_positive)[:4]]\n    top5_scores = scores_positive[np.argsort(-scores_positive)[:4]]\n    output = pd.DataFrame(dict(zip(top5_candidates, top5_scores)), index = [0]).T.reset_index()\n    output.columns = ['Candidate', 'Score']\n    return output       \n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:37:23.243184Z","iopub.execute_input":"2023-05-05T14:37:23.243596Z","iopub.status.idle":"2023-05-05T14:37:23.260052Z","shell.execute_reply.started":"2023-05-05T14:37:23.243562Z","shell.execute_reply":"2023-05-05T14:37:23.258675Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"example_ids = np.random.randint(low = 0, high = len(train_questions)-1, size = 5)\nexamples = np.array(train_questions)[example_ids]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:37:25.143852Z","iopub.execute_input":"2023-05-05T14:37:25.144198Z","iopub.status.idle":"2023-05-05T14:37:27.156140Z","shell.execute_reply.started":"2023-05-05T14:37:25.144168Z","shell.execute_reply":"2023-05-05T14:37:27.155094Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**Fair Approach**","metadata":{}},{"cell_type":"code","source":"print(\"=\"*40, examples[0], \"=\"*40)\nprocess_question(examples[0], model_1, tokenizer_1, \n                 method = 'fair')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T15:52:53.252168Z","iopub.execute_input":"2023-05-05T15:52:53.252610Z","iopub.status.idle":"2023-05-05T16:21:19.124492Z","shell.execute_reply.started":"2023-05-05T15:52:53.252575Z","shell.execute_reply":"2023-05-05T16:21:19.123355Z"},"trusted":true},"execution_count":222,"outputs":[{"name":"stdout","text":"======================================== What is the hardest language for a native English speaker to learn? ========================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1930/1930 [28:23<00:00,  1.13it/s]\n","output_type":"stream"},{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"                                           Candidate     Score\n0  What aspects of English do non-native find dif...  0.990457\n1  What's the most difficult language for a nativ...  0.978208\n2  What is the hardest language for a native Engl...  0.970506\n3  What aspects of English do non-native find the...  0.950073","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Candidate</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What aspects of English do non-native find dif...</td>\n      <td>0.990457</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What's the most difficult language for a nativ...</td>\n      <td>0.978208</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the hardest language for a native Engl...</td>\n      <td>0.970506</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What aspects of English do non-native find the...</td>\n      <td>0.950073</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Random Sampling Approach**","metadata":{}},{"cell_type":"code","source":"print(\"=\"*40, examples[0], \"=\"*40)\nprocess_question(examples[0], model_1, tokenizer_1, \n                 method = 'sampling', n_samples = 100)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T15:49:31.253598Z","iopub.execute_input":"2023-05-05T15:49:31.253962Z","iopub.status.idle":"2023-05-05T15:51:19.136697Z","shell.execute_reply.started":"2023-05-05T15:49:31.253931Z","shell.execute_reply":"2023-05-05T15:51:19.135500Z"},"trusted":true},"execution_count":221,"outputs":[{"name":"stdout","text":"======================================== What is the hardest language for a native English speaker to learn? ========================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [01:45<00:00,  1.06s/it]\n","output_type":"stream"},{"execution_count":221,"output_type":"execute_result","data":{"text/plain":"                                           Candidate     Score\n0  Is English a difficult or easy language to learn?  0.007197\n1           Which language should be learned first ?  0.000598\n2  What is the best way to learn spoken English w...  0.000548\n3      What can I do to improve my English speaking?  0.000522","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Candidate</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Is English a difficult or easy language to learn?</td>\n      <td>0.007197</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which language should be learned first ?</td>\n      <td>0.000598</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the best way to learn spoken English w...</td>\n      <td>0.000548</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What can I do to improve my English speaking?</td>\n      <td>0.000522</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Jaccard Distance Approach**","metadata":{}},{"cell_type":"code","source":"print(\"=\"*40, examples[0], \"=\"*40)\nprocess_question(examples[0], model_1, tokenizer_1, \n                 method = 'restricted', r_size = 25_000)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T15:47:25.677180Z","iopub.execute_input":"2023-05-05T15:47:25.677571Z","iopub.status.idle":"2023-05-05T15:49:11.326812Z","shell.execute_reply.started":"2023-05-05T15:47:25.677537Z","shell.execute_reply":"2023-05-05T15:49:11.325675Z"},"trusted":true},"execution_count":218,"outputs":[{"name":"stdout","text":"======================================== What is the hardest language for a native English speaker to learn? ========================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 98/98 [01:35<00:00,  1.03it/s]\n","output_type":"stream"},{"execution_count":218,"output_type":"execute_result","data":{"text/plain":"                                           Candidate     Score\n0                              What is substitution?  0.978208\n1             How would you know if you are a loner?  0.970506\n2  How can you deal with the street lights while ...  0.010496\n3  How does the universe and quantum physics play...  0.009481","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Candidate</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is substitution?</td>\n      <td>0.978208</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How would you know if you are a loner?</td>\n      <td>0.970506</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How can you deal with the street lights while ...</td>\n      <td>0.010496</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How does the universe and quantum physics play...</td>\n      <td>0.009481</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}